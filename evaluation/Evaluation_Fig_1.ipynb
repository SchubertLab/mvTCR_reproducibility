{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3a051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "#import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557b2efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\mvTCR_repro2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../mvTCR/')\n",
    "import tcr_embedding.utils_training as utils\n",
    "import config.constants_10x as const\n",
    "\n",
    "from tcr_embedding.utils_preprocessing import stratified_group_shuffle_split, group_shuffle_split\n",
    "from tcr_embedding.evaluation.Imputation import run_imputation_evaluation\n",
    "from tcr_embedding.evaluation.Clustering import run_clustering_evaluation\n",
    "from tcr_embedding.evaluation.kNN import run_knn_within_set_evaluation\n",
    "from tcr_embedding.evaluation.WrapperFunctions import get_model_prediction_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af82f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(adata, dataset, split, model, donor=''):\n",
    "    path_model = f'saved_models/journal_2/10x/splits/{model}/10x_donor_{donor}_split_{split}_{model}'\n",
    "    path_model += '.pt'\n",
    "    model = utils.load_model(adata, path_model)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5aa8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def load_10x_data(donor, split, size=False):\n",
    "    adata = utils.load_data('10x')\n",
    "    if str(donor) != 'None':\n",
    "        adata = adata[adata.obs['donor'] == f'donor_{donor}']\n",
    "    else:\n",
    "        enc = OneHotEncoder(sparse=False)\n",
    "        enc.fit(adata.obs['donor'].to_numpy().reshape(-1, 1))\n",
    "        adata.obsm['donor'] = enc.transform(adata.obs['donor'].to_numpy().reshape(-1, 1))\n",
    "    adata = adata[adata.obs['binding_name'].isin(const.HIGH_COUNT_ANTIGENS)]\n",
    "    if split != 'full':\n",
    "        random_seed = split\n",
    "\n",
    "        train_val, test = group_shuffle_split(adata, group_col='clonotype', val_split=0.20, random_seed=random_seed)\n",
    "        train, val = group_shuffle_split(train_val, group_col='clonotype', val_split=0.25, random_seed=random_seed)\n",
    "    \n",
    "        if size:\n",
    "            sc.pp.subsample(train, n_obs=size)\n",
    "\n",
    "        adata.obs['set'] = None\n",
    "        adata.obs.loc[train.obs.index, 'set'] = 'train'\n",
    "        adata.obs.loc[val.obs.index, 'set'] = 'val'\n",
    "        adata.obs.loc[test.obs.index, 'set'] = 'test'\n",
    "        adata = adata[adata.obs['set'].isin(['train', 'val', 'test'])]\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e136d",
   "metadata": {},
   "source": [
    "## 10x Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c26d71b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:15<00:00, 63.16s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [15:29<00:00, 185.84s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [08:42<00:00, 104.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:27<00:00, 29.58s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [42:21<00:00, 508.36s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = '10x'\n",
    "donor = 1\n",
    "metadata = ['binding_name', 'clonotype', 'donor']\n",
    "\n",
    "model_names = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "donors = []\n",
    "for donor in list(range(1, 5)) + ['None']:\n",
    "    for split in tqdm(range(0, 5)):\n",
    "        data = load_10x_data(donor, split)\n",
    "        for model_name in ['concat', 'moe', 'poe', 'tcr', 'rna']:\n",
    "            model = load_model(data, dataset, split, model_name, donor)\n",
    "            test_embedding_func = get_model_prediction_function(model)\n",
    "            for source in ['test']:  #, 'val']:\n",
    "                summary = run_imputation_evaluation(data, test_embedding_func, query_source=source,\n",
    "                                            label_pred='binding_name')\n",
    "                result = summary['knn']['weighted avg']['f1-score']\n",
    "\n",
    "                model_names.append(model_name)\n",
    "                splits.append(split)\n",
    "                metrics.append(f'Prediction {source}')\n",
    "                scores.append(result)\n",
    "                donors.append(donor)\n",
    "\n",
    "            best_nmi = -99\n",
    "            for resolution in [0.01, 0.1, 1.0]:\n",
    "                cluster_result = run_clustering_evaluation(data, test_embedding_func, 'train', name_label='binding_name', \n",
    "                                                   cluster_params={'resolution': resolution, 'num_neighbors': 5})\n",
    "                best_nmi = max(cluster_result['NMI'], best_nmi)\n",
    "            model_names.append(model_name)\n",
    "            splits.append(split)\n",
    "            metrics.append('NMI')\n",
    "            scores.append(best_nmi)  \n",
    "            donors.append(donor)\n",
    "\n",
    "results_10x = {\n",
    "    'model': model_names,\n",
    "    'split': splits,\n",
    "    'metric': metrics,\n",
    "    'score': scores,\n",
    "    'donor': donors,\n",
    "    'dataset': [dataset] * len(splits)\n",
    "}\n",
    "results_10x = pd.DataFrame(results_10x)\n",
    "results_10x.to_csv(f'../results/performance_10x.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce70654",
   "metadata": {},
   "source": [
    "## Minervina Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dd36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_minervina_model(adata, dataset, split, model):\n",
    "    path_model = f'saved_models/journal_2/minervina/splits/{model}/'\n",
    "    path_model += f'minervina_split_{split}_{model}'\n",
    "    path_model += '.pt'\n",
    "    model = utils.load_model(adata, path_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6becfb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def load_minervina_data(split, size=False):\n",
    "    adata = utils.load_data('minervina/01_annotated_data.h5ad')\n",
    "    # subsample to get statistics\n",
    "    random_seed = split\n",
    "    train_val, test = group_shuffle_split(adata, group_col='clonotype', val_split=0.20, random_seed=random_seed)\n",
    "    train, val = group_shuffle_split(train_val, group_col='clonotype', val_split=0.25, random_seed=random_seed)\n",
    "    \n",
    "    if size:\n",
    "        sc.pp.subsample(train, n_obs=size)\n",
    "            \n",
    "    adata.obs['set'] = None\n",
    "    adata.obs.loc[train.obs.index, 'set'] = 'train'\n",
    "    adata.obs.loc[val.obs.index, 'set'] = 'val'\n",
    "    adata.obs.loc[test.obs.index, 'set'] = 'test'\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea7c924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:22<00:00, 40.59s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = 'minervina'\n",
    "metadata = ['epitope']\n",
    "\n",
    "model_names = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "\n",
    "for split in tqdm(range(0, 5)):\n",
    "    data = load_minervina_data(split)\n",
    "    for model_name in ['concat', 'moe', 'poe', 'tcr', 'rna']:\n",
    "        model = load_minervina_model(data, dataset, split, model_name)\n",
    "        test_embedding_func = get_model_prediction_function(model)\n",
    "        for source in ['test']:  #, 'val']:\n",
    "            summary = run_imputation_evaluation(data, test_embedding_func, query_source=source,\n",
    "                                        label_pred='epitope')\n",
    "            result = summary['knn']['weighted avg']['f1-score']\n",
    "\n",
    "            model_names.append(model_name)\n",
    "            splits.append(split)\n",
    "            metrics.append(f'Prediction {source}')\n",
    "            scores.append(result)\n",
    "            donors.append(donor)\n",
    "\n",
    "        best_nmi = -99\n",
    "        for resolution in [0.01, 0.1, 1.0]:\n",
    "            cluster_result = run_clustering_evaluation(data, test_embedding_func, 'train', name_label='epitope', \n",
    "                                               cluster_params={'resolution': resolution, 'num_neighbors': 5})\n",
    "            best_nmi = max(cluster_result['NMI'], best_nmi)\n",
    "        model_names.append(model_name)\n",
    "        splits.append(split)\n",
    "        metrics.append('NMI')\n",
    "        scores.append(best_nmi)  \n",
    "\n",
    "results_min = {\n",
    "    'model': model_names,\n",
    "    'split': splits,\n",
    "    'metric': metrics,\n",
    "    'score': scores,\n",
    "    'donor': ['-'] * len(splits),\n",
    "    'dataset': [dataset] * len(splits)\n",
    "}\n",
    "results_min = pd.DataFrame(results_min)\n",
    "results_min.to_csv(f'../results/performance_minervina.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734a43f",
   "metadata": {},
   "source": [
    "## Contribution Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb9451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.56s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:07<00:00, 13.56s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:55<00:00, 11.06s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:38<00:00,  7.64s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:15<00:00, 27.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:15<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "splits = []\n",
    "donors = []\n",
    "scores = []\n",
    "\n",
    "for donor in list(range(1, 5)) + ['None']:\n",
    "    for split in tqdm(range(0, 5)):\n",
    "        data = load_10x_data(donor, split)\n",
    "        \n",
    "        model = load_model(data, '10x', split, 'moe', donor)        \n",
    "        model.get_modality_contribution(data)\n",
    "        \n",
    "        result = data.obs['contribution_tcr-rna'].values.mean()\n",
    "        \n",
    "        splits.append(split)\n",
    "        scores.append(result)\n",
    "        donors.append(donor)\n",
    "        \n",
    "for split in tqdm(range(0, 5)):\n",
    "    data = load_minervina_data(split)\n",
    "    \n",
    "    model = load_minervina_model(data, 'minervina', split, 'moe')\n",
    "    model.get_modality_contribution(data)\n",
    "\n",
    "    result = data.obs['contribution_tcr-rna'].values.mean()\n",
    "\n",
    "    splits.append(split)\n",
    "    scores.append(result)\n",
    "    donors.append('minervina')\n",
    "\n",
    "results_contributions = {\n",
    "    'split': splits,\n",
    "    'score': scores,\n",
    "    'donor': donors,\n",
    "}\n",
    "results_contributions = pd.DataFrame(results_contributions)\n",
    "results_contributions.to_csv(f'../results/contribution_10x_minervina.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f26c84",
   "metadata": {},
   "source": [
    "## Dataset size tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6f25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_size(adata, dataset, split, size, donor=''):\n",
    "    path_model = f'saved_models/journal_2/10x/data_size/10x_donor_{donor}_split_{split}_moe_{size}'\n",
    "    path_model += '.pt'\n",
    "    model = utils.load_model(adata, path_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edaf8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_2_size = {\n",
    "    'None': [100, 500, 1000, 2500, 5000, 10000, 15000],\n",
    "    1: [100, 500, 1000, 2500, 5000],\n",
    "    2: [100, 500, 1000, 2500, 5000, 10000, 15000],\n",
    "    3: [100, 500, 1000, 2500, 5000, 10000],\n",
    "    4: [100, 500, 1000, 2500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414664e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [07:58<00:00, 95.78s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [29:42<00:00, 356.56s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [15:22<00:00, 184.59s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:52<00:00, 46.45s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:09:14<00:00, 830.91s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = '10x'\n",
    "metadata = ['binding_name', 'clonotype', 'donor']\n",
    "\n",
    "sizes = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "donors = []\n",
    "for donor in list(range(1, 5)) + ['None']:\n",
    "    for split in tqdm(range(0, 5)):\n",
    "        for size in donor_2_size[donor]:\n",
    "            data = load_10x_data(donor, split)\n",
    "            model = load_model_size(data, dataset, split, size, donor)\n",
    "            test_embedding_func = get_model_prediction_function(model)\n",
    "            for source in ['test']:  #, 'val']:\n",
    "                summary = run_imputation_evaluation(data, test_embedding_func, query_source=source,\n",
    "                                            label_pred='binding_name')\n",
    "                result = summary['knn']['weighted avg']['f1-score']\n",
    "\n",
    "                sizes.append(size)\n",
    "                splits.append(split)\n",
    "                metrics.append(f'Prediction {source}')\n",
    "                scores.append(result)\n",
    "                donors.append(donor)\n",
    "\n",
    "            best_nmi = -99\n",
    "            for resolution in [0.01, 0.1, 1.0]:\n",
    "                cluster_result = run_clustering_evaluation(data, test_embedding_func, 'train', name_label='binding_name', \n",
    "                                                   cluster_params={'resolution': resolution, 'num_neighbors': 5})\n",
    "                best_nmi = max(cluster_result['NMI'], best_nmi)\n",
    "            sizes.append(size)\n",
    "            splits.append(split)\n",
    "            metrics.append('NMI')\n",
    "            scores.append(best_nmi)  \n",
    "            donors.append(donor)\n",
    "\n",
    "results_10x_size = {\n",
    "    'size': sizes,\n",
    "    'split': splits,\n",
    "    'metric': metrics,\n",
    "    'score': scores,\n",
    "    'donor': donors\n",
    "}\n",
    "results_10x_size = pd.DataFrame(results_10x_size)\n",
    "results_10x_size.to_csv(f'../results/performance_10x_datasize.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57768445",
   "metadata": {},
   "source": [
    "### Minervina Datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68894de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_minervina_model_size(adata, dataset, split, size, donor=''):\n",
    "    path_model = f'saved_models/journal_2/minervina/data_size/minervina_split_{split}_moe_{size}'\n",
    "    path_model += '.pt'\n",
    "    model = utils.load_model(adata, path_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8386b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minervina_sizes = [100, 500, 1000, 2500, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38ebf688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:40<00:00, 56.08s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = 'minervina'\n",
    "metadata = ['epitope']\n",
    "\n",
    "sizes = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "\n",
    "for split in tqdm(range(0, 5)):\n",
    "    for size in minervina_sizes:\n",
    "        data = load_minervina_data(split)\n",
    "        model = load_minervina_model_size(data, dataset, split, size)\n",
    "        test_embedding_func = get_model_prediction_function(model)\n",
    "        for source in ['test']:  #, 'val']:\n",
    "            summary = run_imputation_evaluation(data, test_embedding_func, query_source=source,\n",
    "                                        label_pred='epitope')\n",
    "            result = summary['knn']['weighted avg']['f1-score']\n",
    "\n",
    "            sizes.append(size)\n",
    "            splits.append(split)\n",
    "            metrics.append(f'Prediction {source}')\n",
    "            scores.append(result)\n",
    "\n",
    "        best_nmi = -99\n",
    "        for resolution in [0.01, 0.1, 1.0]:\n",
    "            cluster_result = run_clustering_evaluation(data, test_embedding_func, 'train', name_label='epitope', \n",
    "                                               cluster_params={'resolution': resolution, 'num_neighbors': 5})\n",
    "            best_nmi = max(cluster_result['NMI'], best_nmi)\n",
    "        sizes.append(size)\n",
    "        splits.append(split)\n",
    "        metrics.append('NMI')\n",
    "        scores.append(best_nmi)  \n",
    "\n",
    "results_min_size = {\n",
    "    'size': sizes,\n",
    "    'split': splits,\n",
    "    'metric': metrics,\n",
    "    'score': scores,\n",
    "    'donor': [dataset] * len(splits)\n",
    "}\n",
    "results_min_size = pd.DataFrame(results_min_size)\n",
    "results_min_size.to_csv(f'../results/performance_minervina_datasize.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d3365",
   "metadata": {},
   "source": [
    "## Write Supplemantary Material S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca37b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = '../results/supplement/S1_benchmarking.xlsx'\n",
    "results_10x.to_excel(path_out, sheet_name='Specificity_10x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d12a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(path_out, mode='a') as writer: \n",
    "    results_min.to_excel(writer, sheet_name='Specificity_Minervina')\n",
    "    \n",
    "    results_10x_size.to_excel(writer, sheet_name='Datasize_10x')\n",
    "    results_min_size.to_excel(writer, sheet_name='Datasize_Minervina')\n",
    "    \n",
    "    results_contributions.to_excel(writer, sheet_name='TCR-Contribution_10x_Minervina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd819e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mvTCR_repro2]",
   "language": "python",
   "name": "conda-env-mvTCR_repro2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
